Title: Prepare for the Terraform Associate (003) Certification Exam in 2025
Date: 2025-11-02
Category: Knowledge Base
Tags: iac


# My little experience to prepare for the Terraform Associate Exam in 2025
- Why exam, do you think certification is the golden ticket to help you get a better job???
- What context you should know before take the exam
- Practice without any bucks spent!
- Resource for learning/preparing for the exam!

Let's begin!


# 1. Why exam, do you think certification is the golden ticket to help you get a better job?
The context below is just my personal opinion:

- To be honest, certification just shows that you know the basics about and maybe a little achievement, nothing more.
- It will not help you get a better job or increase salary, the important thing is when you prepare for the exam, you learned how it works, that is the point i want to tell (at least for my case, maybe not for your case).
- When you have no real project to show during an interview, better to have a certification than nothing xD
- Last, certifications are not golden tickets; it is the only thing i proved to myself that i finished that course properly and know the basics, specifically here is Terraform Associate level.


# 2. What context you should know before take the exam
I also write this to myself to remind what i need to remember for exam, haha. This section could contain a lot of text. I will use aws provider as example.

## Basic concept of Terraform

### Provider Plugin
It allows terraform manage 1 external API, when we run terraform init, plugins needed for provider will automatically download from Terraform Registry (default) or other if configured and save into local directory **.terraform/providers/**

### Resource Blocks
Resource block describe 1 or multiple infrastructure object

```hcl
resource "aws_instance" "myec2" {
    ami = "ami-123456"
    instance_type = "t2.micro"
}
```

**Key points about Resource Blocks:**

- **Resource type**: `aws_instance`
- **Resource name**: `myec2` 
- **Resource ID format**: `<resource_type>.<resource_name>` â†’ `aws_instance.myec2`
- Resource type and resource name together serving for resource identity, so it must be unique (resource name)
- Use this ID for reference: **aws_instance.myec2.id**
- You can not use resource type `aws_instance` in provider `azurerm` xD


### Terraform Destroy
- Destroy all: `terraform destroy`
- Destroy specific resource: `terraform destroy -target aws_instance.myec2`

### Terraform State file - terraform.tfstate (this is important)
- Terraform saves state of infra created to tf files. This state allow terraform map resource with current config
- After creating resources, terraform will save information of resource (with example of ec2 instance) like instance-id, instance-type, security-group... Lets take a look at example below
```terraform
"resource" : [
    {
        "type" : "aws_instance",
        "name" : "myec2"
    }
]
```
- And more than that, tfstate save actual state (in terraform.tfstate) of live resource (desired state: in .tf config files). Recommendation: never ever manually edit this file!
- If you accident edit this file like remove state, if you run terraform apply again it will create another ec2 instance for example.
- State files contain sensitive data --> need to secure. Recommend to use remote backend (S3, Terraform Cloud) instead of local.
- Use state locking to avoid conflict when working with a team!

### AWS Provider - Authentication Configuration
- Default config: Linux/MacOS: "$HOME/.aws/config" && "$HOME/.aws/credentials"
- You can install and setup `awscli` to auth with terraform, no need to set secret/access key inside terraform xD
- Or recommend use env: AWS_ACCESS_KEY_ID + AWS_SECRET_ACCESS_KEY + AWS_REGION

## Function, Data Types, Resource Attributes, Output Values, Variables, Meta-Argument

### Function
- So for this section i will introduce `terraform console`, you can imagine it works like `python console` xD. For example:

```bash
terraform console
> max(10,20,30)
30
> min(5,10,15)
5
> length(["a","b","c"])
3
```

- You can always test in terraform console before write config
```bash
terraform console
> file("./iam_policy.json")
# will print content of iam_policy.json file
```

- Read and learn more about built-in function of HCL here: [**Terraform Functions**](https://developer.hashicorp.com/terraform/language/functions)
- Terraform doesn't support user-defined function, only built-in, remember this!


### Data Types
| Data Type | Description | Example |
|-----------|-------------|---------|
| `string` | Sequence of Unicode characters representing text | `"hello"`, `"us-east-1"` |
| `number` | Numeric value (can be integer or float) | `42`, `3.14`, `-10` |
| `bool` | Boolean value | `true`, `false` |
| `list` (or `tuple`) | Ordered sequence of values | ["us-west-1a", "us-west-1b"], [1, 2, 3] |
| `set` | Unordered collection of unique values | `["a", "b", "c"]` (no duplicates) |
| `map` (or `object`) | Collection of key-value pairs | `{name = "web", port = 80}` |
| `null` | Represents absence of a value | `null` |
| `any` | Placeholder for any type (used in variable definitions) | Can accept any of the above types |

**Reference:** [**Terraform Type Constraints**](https://developer.hashicorp.com/terraform/plugin/framework/handling-data/types)


### Resource Attributes
- Time to document like a pro guy, haha. [**AWS Instance Resource**](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/instance)
- We can understand attributes like `ami`, `instance_type`, `tags` are attribute of aws_instance resource. 
- Attributes can be arguments (inputs) or exported attributes (outputs after creation)

### Output Values
- Output values: display after run terraform apply. For example
```hcl
# Display vpc id value
output "vpc_id" {
  value = aws_vpc.kienlt_first_vpc.id
}
####
## Outputs:
## vpc_id = "vpc-0b806f82efdbe8d5f"
####
```
- Without define `.id`, it will display all attributes of resource `aws_vpc.kienlt_first_vpc`

### Cross-Project Outputs (Remote State Data Source)

- Project B can read outputs from Project A using **`terraform_remote_state`** data source
- Project A's state must be stored in **remote backend** (S3, Terraform Cloud, etc.)
- Example:

**Project A** (outputs in remote state):
```hcl
output "vpc_id" {
  value = aws_vpc.main.id
}
```

**Project B** (reads from Project A):
```hcl
data "terraform_remote_state" "project_a" {
  backend = "s3"
  config = {
    bucket = "my-terraform-state"
    key    = "project-a/terraform.tfstate"
    region = "us-east-1"
  }
}

resource "aws_instance" "web" {
  vpc_id = data.terraform_remote_state.project_a.outputs.vpc_id
}
```

**Key points:**

- Must use **remote backend** (local state won't work)
- Access via `data.terraform_remote_state.<name>.outputs.<output_name>`
- Common pattern for **shared infrastructure** (VPC, networks, etc.)

**Reference:** [terraform_remote_state](https://developer.hashicorp.com/terraform/language/state/remote-state-data)


### Terraform Variables
- Use to handle static value without repeat!
- Central management, edit in 1 file, no need to edit terraform code

#### Variable Definition File (TFVARS)
- Hashicorp recommend create file separated with name of *.tfvars to define all variable in a project
- Manage variable in production env is 1 of way to achieve code clean and reuseable
- For example:
```hcl
# variables.tf
variable "instance_type" {
  type = string
}

variable "instance_count" {
  type = number
}
```

```hcl
# example.tfvars
instance_type  = "t2.micro"
instance_count = 1
```

Deploy example:
```bash
terraform plan -var-file="example.tfvars"
terraform apply -var-file="example.tfvars"
```

- File terraform.tfvars or *.auto.tfvars will auto load, no need to define flag `-var-file`
- File *.tfvars need to define with flag `-var-file`
- Common practice

```
project/
â”œâ”€â”€ environments/
â”‚   â”œâ”€â”€ dev/
â”‚   â”‚   â””â”€â”€ terraform.tfvars
â”‚   â”œâ”€â”€ prod/
â”‚   â”‚   â””â”€â”€ terraform.tfvars
â”œâ”€â”€ modules/
â””â”€â”€ main.tf
```

#### Variable definition precedence
- This question could be appear in exam
- Priority from highest (5) to lowest (1) xD
- **1. Environment Variable**
- **2. terraform.tfvars file if exists**
- **3. terraform.tfvars.json file if exists**
- **4. *.auto.tfvars or *.auto.tfvars.json**
- **5. From cli: -var and -var-file**

### Meta-Argument
- [Meta-Argument Documents](https://developer.hashicorp.com/terraform/language/meta-arguments)
- I will show 2 popular example i like:

#### Count
- Sometime you want to create multiple object with type without repeat resource block. For example
```hcl
resource "aws_instance" "local_resource_name" {
    ami = "ami-1234"
    instance_type = "t2.micro"
    count = 3 # will create 3 instances like this!
}
```
- Notice that `count` argument works with multiple resource, not only ec2 instance. When resources are created, we can access data expected output like this:
```
aws_instance.local_resource_name[0]
aws_instance.local_resource_name[1]
aws_instance.local_resource_name[2]
```

### for_each
- With count, we can not create resource with different name (aws_instance), only index (0,1,2)
- If we want multiple instance and each instance have different name --> use `for_each`
- Remember `Name` is special tag, display in first column in EC2 console
```hcl
âŒ count - only index, same instance name
resource "aws_instance" "server" {
  count         = 3
  ami           = "ami-1234"
  instance_type = "t2.micro"
  tags = {
    Name = "server-${count.index}"  # server-0, server-1, server-2
  }
}

âœ… for_each - name can be customize
resource "aws_instance" "server" {
  for_each      = toset(["web", "api", "db"])
  ami           = "ami-1234"
  instance_type = "t2.micro"
  tags = {
    Name = each.key  # web, api, db
  }
}

# Access:
# aws_instance.server["web"]
# aws_instance.server["api"]
# aws_instance.server["db"]
```

- So, use `for_each` over `count` when need flexible naming/config!

## Terraform Provisioner
- This is known as removed from exam?
- Even Terraform is not recommend use this, but in some scenario, you can not use Ansible/Saltstack, here you go...
- Provisioners used to `execute scripts on a local or remote machine` as part of resource creation or Destruction!
- 2 major types of provisioners: local-exec and remote-exec

### Local-exec provisioner
- Invoke local execute after resource created, like after EC2 created, get ip of EC2 instance save to file called server_ip.txt in where we run terraform apply

### remote-exec provisioner
- invoke scripts or run commands directly on remote-server

### Defining provisioner
- Need to be **define inside resource block**
- For example remote-exec
```hcl
resource "aws_instance" "myec2" {
    ami = "ami-1234"
    instance_type = "t2.micro"

    # Bonus: add connection block for remote exec
    connection {
        type = "ssh"
        user = "ec2-user"
        private_key = file("./terraform-key.pem")
        host = self.public_ip
    }

    provisioner "remote-exec" {
        inline = [
            "sudo yum install -y nginx",
            "sudo systemctl start nginx"
        ]
    }
}
```

- For example local-exec: we can understand $self is a way to call attribute of resource aws_instance after created!.
```hcl
resource "aws_instance" "myec2" {
    ami = "ami-1234"
    instance_type = "t2.micro"

    # Run after created!
    provisioner "local-exec" {
        command = "echo ${self.private_ip} >> server_ip.txt"
    }
}
```

- Remember we can add 1 or more provisioner local-exec inside 1 resource block!
- Provisioner run **only during creation (default)**
- Want to run when destroy? --> Add `when = destroy`


## Terraform Module
- Till this line, i'm so lazy to continue even this is one of really important component in Terraform, so i will go for it real quick T_T
- Module is extremely important for DRY code ( Don't Repeat Yourself!)
- Challenge when we have no idea about module:
    - Everytime we create ec2 instance, there is 1 resource block added, 10 teams 10 resource block?
    - When AWS provider changed, we need to change in terraform config of 10 teams?
    - No standard for 10 teams? Hard to management!
- Terraform module allow manage resource configuration in central, make it works in multiple project
- Instead write module from beginning, we could use multiple module available and ready to use.
- When not to use module? You want to write your own module, you think there is no module better than your xDD. Otherwise, keep use module instead of write from scratch!
- [View more module here](https://registry.terraform.io/browse/modules)
- When run: `terraform init`, it will download module code and provider into local folder `.terraform`, module code is github repo!

And many more...

## Terraform Workspace, remote state management, sensitive parameter, multiple provider configuration, dependency lock file, terraform cloud
They are all keyword you need to learn and understand in order to have well prepared state for the exam, but if write all of them here, this post would contains more than 1000 lines T_T.



# 3. Practice without any bucks spent
- TLDR: Use security group and VPC to practice with AWS, they will not cost any money!

- main.tf
```hcl
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 6.0"
    }
  }
}

# Configure the AWS Provider
provider "aws" {
  region = "ap-southeast-1"
}

# Create VPC First
resource "aws_vpc" "kienlt_first_vpc" {
  cidr_block = "10.0.0.0/22"

  tags = {
    Name = var.vpc_name
  }
}

resource "aws_security_group" "kienlt_first_sg" {
  name        = "kienlt_first_sg"
  description = "Security group for KienLT first VPC"
  vpc_id      = aws_vpc.kienlt_first_vpc.id

  ingress {
    description = "Allow HTTPS"
    from_port   = var.https_port
    to_port     = var.https_port
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  ingress {
    description = "Allow ssh from VPC Only"
    from_port   = var.ssh_port
    to_port     = var.ssh_port
    protocol    = "tcp"
    cidr_blocks = [aws_vpc.kienlt_first_vpc.cidr_block]
  }

  egress {
    description = "Allow all outbound"
    from_port   = 0
    to_port     = 0
    protocol    = "-1"          # All Protocol
    cidr_blocks = ["0.0.0.0/0"] # # All ports/destinations!
  }
}
```

- variables.tf
```hcl
variable "vpc_name" {
  type        = string
  default     = "kienlt first vpc via variable"
  description = "Description here is for document!"
}

variable "ssh_port" {
  default = 22
}

variable "https_port" {
  default = 443
}
```

- outputs.tf
```hcl
output "vpc_id" {
  value = aws_vpc.kienlt_first_vpc.id
}

output "security_group_id" {
  value = aws_security_group.kienlt_first_sg.id
}
```

Remember to destroy after practice, VPC + SG = free tier!

# 4. Resources for learning/preparing for the exam
- Well, they're all available in Terraform documentation, but for the best and most effective preparation, learn via a structured course.
- Which course did I choose? [HashiCorp Certified: Terraform Associate 2025](https://www.udemy.com/course/terraform-beginner-to-advanced/)
- Fun fact: I've listened to so much India-English from tech tutorials that by 2025, I don't need subtitles anymore! ðŸ˜„
